---
output: rmarkdown::github_document
bibliography: ./inst/REFERENCES.bib
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    fig.path = "man/figures/README-",
    out.width = "100%",
    tidy = "styler"
)
library(fastGHS)
library(jointGHS)
library(foreach)
library(tailoredGlasso)
```


<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
<!--[![codecov](https://codecov.io/gh/Camiling/JoStARS/branch/main/graph/badge.svg?token=QL5ZW3RQZD)](https://codecov.io/gh/Camiling/JoStARS) -->
<!--[![R build status](https://github.com/Camiling/JoStARS/workflows/R-CMD-check/badge.svg)](https://github.com/Camiling/JoStARS/actions) -->
<!-- badges: end -->

<!-- IF ON CRAN [![CRAN_Status_Badge](https://www.r-pkg.org/badges/version-last-release/shapr)]
[![CRAN_Downloads_Badge](https://cranlogs.r-pkg.org/badges/grand-total/shapr)]---->
<!--PAPER HERE [![DOI](https://joss.theoj.org/papers/10.21105/joss.02027/status.svg)]---->


# `jointGHS` <img src="man/figures/jointGHSlogo.png" align="right" height="150"/>


The `jointGHS` package implements the joint graphical horseshoe for multiple network estimation, in the setting of Gaussian graphical models. The package provides a scalable expectation conditional maximisation (ECM) algorithm for obtaining the posterior mode of the precision matrices (inverse covariance matrices). The non-zero off-diagonal elements of the resulting matrices correspond to the edges identified. The method borrows information between networks in order to increase statistical power, while ensuring information is only shared to the degree that it improves the network estimates. The method takes a list of data matrices for which separate graphs are to be inferred, and shares edge wise information between them through a common edge-specific latent variable. The resulting method captures what is common between the networks while preserving their differences, and can be used agnostically for any level of similarity between the networks. 



## Installation

This package requires the package `fastGHS` to be installed. To install the current development version of both packages, use

```{r, eval = FALSE}
remotes::install_github("camiling/fastGHS")
remotes::install_github("camiling/jointGHS")
```

If you would like to install all packages of the models we currently support, use

```{r, eval = FALSE}
remotes::install_github("camiling/jointGHS", dependencies = TRUE)
```


If you would also like to build and view the vignette locally, use 

```{r, eval = FALSE}
remotes::install_github("camiling/jointGHS", dependencies = TRUE, build_vignettes = TRUE)
browseVignettes("jointGHS")
```


## Example


The main function `jointGHS` takes a list of $K$ data matrices, each of dimension $n_k \times p$ where $n_k$ is the sample size of data set $k$, for which separate graphs are to be inferred. The methods estimates the posterior mode of each precision matrix in the joint graphical horseshoe. 

The following examples show how `jointGHS` identifies the common edges for a set of $K=2$ graphs, as well as the individual edges on the network-level, and returns the resulting precision matrix estimates. One example with $K=2$ data sets drawn from the same distribution, and one with $K=2$ data sets drawn from completely unrelated distributions, is shown. In the first case, jointGHS identifies a large number of common edges. This results in high precision considering the high dimensionality of the problem. In the latter case, hardly any common edges are found and little similarity between the two graphs is encouraged. 

The data is generated using the R package `huge` (@huge), as it includes functionality for generating data from a Gaussian graphical model. The networks we generate are *scale-free*, which is a known trait in many real-life networks such as genomic networks (@kolaczyk09).

```{r, warning = FALSE}
#  example 1: scale-free data where the data sets are from the same distribution
set.seed(123)
n1 = 60 # let there be different number of samples in each data set
n2 = 50 
p <- 20 # Still very high-dimensional: 190 potential edges 
dat <- huge::huge.generator(n = n1, d = p, graph = "scale-free")
dat$sparsity # true sparsity level
prec.mat <- dat$omega # the true precision matrix of both data sets
x1 = MASS::mvrnorm(n1, mu=rep(0,p),Sigma=dat$sigma) # data set 1
x2 = MASS::mvrnorm(n2, mu=rep(0,p),Sigma=dat$sigma) # data set 2
Y=list(x1, x2)
res <- jointGHS(Y, epsilon = 1e-3, AIC_eps = 1e-3) 
adj.mat1 <- abs(cov2cor(res$theta[[1]])) > 1e-5  # the estimated adjacency matrix of graph 1
adj.mat2 <- abs(cov2cor(res$theta[[2]])) > 1e-5 # the estimated adjacency matrix of graph 2
sparsity(adj.mat1) # the sparsities of the estimated precision matrices
sparsity(adj.mat2)
# Look at precision of inferred graphs
precision(abs(prec.mat) > 1e-7, adj.mat1)
precision(abs(prec.mat) > 1e-7, adj.mat2)
# Save for plotting
adj.mat1.1 = adj.mat1
adj.mat2.1 = adj.mat2
# example 2: scale-free data where where the data sets are from completely unrelated distributions
set.seed(123)
n1 <- 60 
n2 <- 50
p <- 20
dat1 <- huge::huge.generator(n = n1, d = p, graph = "scale-free")
dat2 <- huge::huge.generator(n = n2, d = p, graph = "scale-free") # second graph is completely unrelated
dat1$sparsity # true sparsity level for graph 1
dat2$sparsity # true sparsity level for graph 2
prec.mat1 <- dat1$omega # the true precision matrix of data set 1
prec.mat2 <- dat2$omega # the true precision matrix of data set 2
x1 = MASS::mvrnorm(n1, mu=rep(0,p),Sigma=dat1$sigma)
x2 = MASS::mvrnorm(n2, mu=rep(0,p),Sigma=dat2$sigma)
Y = list(x1, x2)
res <- jointGHS(Y, epsilon = 1e-3, AIC_eps = 1e-3)
adj.mat1 <- abs(cov2cor(res$theta[[1]])) > 1e-5  # the estimated adjacency matrix of graph 1
adj.mat2 <- abs(cov2cor(res$theta[[2]])) > 1e-5 # the estimated adjacency matrix of graph 2
sparsity(adj.mat1) # the sparsities of the estimated precision matrices
sparsity(adj.mat2) # Very sparse as little data is available, and no shared information
# slightly lower precision as no information could be borrowed across classes, but still very high
precision(abs(prec.mat) > 1e-7, adj.mat1)
precision(abs(prec.mat) > 1e-7, adj.mat2)

```

The resulting jointGHS graphs can be visualised with functions from the `network` and `ggnet2` libraries. 


```{r,fig.align='center', out.width='60%',results='hide',warning=FALSE}
set.seed(1234)
net1 =network::network(adj.mat1.1)
net2 =network::network(adj.mat2.1)
g1 = GGally::ggnet2(net1,alpha=0.9,color = 'darkblue')
g2 = GGally::ggnet2(net2,alpha=0.9,color = 'darkblue')
ggpubr::ggarrange(g1,g2,ncol=2,nrow=1)
```


## Contribution

All feedback and suggestions are very welcome. If you have any questions or comments, feel
free to open an issue [here](https://github.com/Camiling/jointGHS/issues). 



## References
